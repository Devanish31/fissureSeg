{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d1ace2",
   "metadata": {},
   "source": [
    "## 3D postprocessing of Chartis lobe segmentation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f16049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import label, binary_dilation\n",
    "from pathlib import Path\n",
    "\n",
    "# === Directories ===\n",
    "input_dir = r\"------ INSERT PATH HERE ------\"\n",
    "output_dir = r\"------ INSERT PATH HERE ------\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Function to assign an isolated component to the neighboring label with largest contact ===\n",
    "def reassign_to_largest_border_component(island_mask, full_mask):\n",
    "    dilated = binary_dilation(island_mask, iterations=1)\n",
    "    border_voxels = dilated & (full_mask > 0) & (~island_mask)\n",
    "    neighbor_labels, counts = np.unique(full_mask[border_voxels], return_counts=True)\n",
    "    if len(counts) == 0:\n",
    "        return 0  # assign to background\n",
    "    return neighbor_labels[np.argmax(counts)]\n",
    "\n",
    "# === Main postprocessing function ===\n",
    "def remove_isolated_components(filepath, output_dir):\n",
    "    img = nib.load(filepath)\n",
    "    data = img.get_fdata().astype(np.uint8)\n",
    "    new_data = np.zeros_like(data)\n",
    "\n",
    "    label_changes = {}\n",
    "    to_background_volumes = {}\n",
    "    total_voxels_changed = 0\n",
    "\n",
    "    for label_id in range(1, 6):  # Labels 1 to 5\n",
    "        binary = (data == label_id)\n",
    "        if not np.any(binary):\n",
    "            continue\n",
    "        labeled_cc, num = label(binary)\n",
    "        sizes = np.bincount(labeled_cc.ravel())\n",
    "        sizes[0] = 0\n",
    "        if len(sizes) == 1:\n",
    "            new_data[labeled_cc == 1] = label_id\n",
    "            continue\n",
    "        largest_cc = np.argmax(sizes)\n",
    "        new_data[labeled_cc == largest_cc] = label_id\n",
    "        for i in range(1, num + 1):\n",
    "            if i == largest_cc:\n",
    "                continue\n",
    "            island_mask = (labeled_cc == i)\n",
    "            new_label = reassign_to_largest_border_component(island_mask, data)\n",
    "            vol = np.sum(island_mask)\n",
    "            total_voxels_changed += vol\n",
    "            if new_label == 0:\n",
    "                to_background_volumes[filepath.name] = to_background_volumes.get(filepath.name, 0) + vol\n",
    "            else:\n",
    "                key = (filepath.name, label_id, new_label)\n",
    "                label_changes[key] = label_changes.get(key, 0) + vol\n",
    "            new_data[island_mask] = new_label\n",
    "\n",
    "    out_path = os.path.join(output_dir, os.path.basename(filepath))\n",
    "    nib.save(nib.Nifti1Image(new_data, img.affine, img.header), out_path)\n",
    "    return label_changes, to_background_volumes, total_voxels_changed\n",
    "\n",
    "# === Process all files ===\n",
    "all_files = list(Path(input_dir).glob(\"*.nii.gz\"))\n",
    "total_label_changes = {}\n",
    "total_bg_changes = {}\n",
    "\n",
    "for f in all_files:\n",
    "    out_path = Path(output_dir) / f.name\n",
    "    if out_path.exists():\n",
    "        print(f\"‚è≠Ô∏è Skipping {f.name} ‚Äî already processed.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üîÑ Processing {f.name} ...\")\n",
    "    label_chg, bg_chg, total_changed = remove_isolated_components(f, output_dir)\n",
    "    for k, v in label_chg.items():\n",
    "        total_label_changes[k] = total_label_changes.get(k, 0) + v\n",
    "    for k, v in bg_chg.items():\n",
    "        total_bg_changes[k] = total_bg_changes.get(k, 0) + v\n",
    "    print(f\"‚úÖ Done {f.name} ‚Äî total voxels reassigned: {total_changed}\")\n",
    "\n",
    "# === Summary ===\n",
    "print(\"\\nüîù Top 5 conversions from one label to another:\")\n",
    "for (name, from_label, to_label), vol in sorted(total_label_changes.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{name}: {vol} voxels from label {from_label} ‚Üí {to_label}\")\n",
    "\n",
    "print(\"\\nüîù Top 5 conversions from label to background:\")\n",
    "for name, vol in sorted(total_bg_changes.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{name}: {vol} voxels converted to background\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762cbfa1",
   "metadata": {},
   "source": [
    "## Calculating the fissure completeness of Chartis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2db36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, nibabel as nib, pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚îÄ‚îÄ Input paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "root_dir = r\"------ INSERT PATH HERE ------\"\n",
    "pred_dir = os.path.join(root_dir, \"Pred\")\n",
    "\n",
    "dirs = {\n",
    "    \"LOF\": os.path.join(pred_dir, \"pred_folder_LOF134_best5000\"),\n",
    "    \"ROF\": os.path.join(pred_dir, \"pred_folder_ROF134_best5000\"),\n",
    "    \"RHF\": os.path.join(pred_dir, \"pred_folder_RHF134_best5000\"),\n",
    "}\n",
    "lobe_dir = os.path.join(pred_dir, \"pred_folder_lobes134_best25003dEdited\")\n",
    "out_xls  = os.path.join(pred_dir, \"fissure_completeness_all_columnwise.xlsx\")\n",
    "\n",
    "# ‚îÄ‚îÄ Algorithm params ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "z_window, max_search, max_gap = 5, 4, 5\n",
    "junctions = {\n",
    "    \"LOF\": (4, 5),\n",
    "    \"RHF\": (1, 2),\n",
    "    \"ROF1\": (1, 3),\n",
    "    \"ROF2\": (2, 3)\n",
    "}\n",
    "\n",
    "def get_covered_and_total(fiss, lob, A, B):\n",
    "    h, n_slices, w = lob.shape\n",
    "    covered = total = 0\n",
    "    for y in range(n_slices):\n",
    "        lob_sl, fiss_sl = lob[:, y, :], fiss[:, y, :]\n",
    "        prevA = prevB = None\n",
    "        for x in range(h):\n",
    "            col = lob_sl[x, :]\n",
    "            if A not in col or B not in col:\n",
    "                continue\n",
    "            candA = [z for z in np.where(col == A)[0] if np.any(col[max(z-max_search,0): z+max_search+1] == B)]\n",
    "            candB = [z for z in np.where(col == B)[0] if np.any(col[max(z-max_search,0): z+max_search+1] == A)]\n",
    "            border_z = []\n",
    "            if candA:\n",
    "                zA = min(candA)\n",
    "                if prevA is None or abs(zA-prevA) <= max_gap:\n",
    "                    border_z.append(zA); prevA = zA\n",
    "                else: prevA = None\n",
    "            if candB:\n",
    "                zB = max(candB)\n",
    "                if prevB is None or abs(zB-prevB) <= max_gap:\n",
    "                    border_z.append(zB); prevB = zB\n",
    "                else: prevB = None\n",
    "            for z in border_z:\n",
    "                total += 1\n",
    "                for dz in range(-z_window, z_window+1):\n",
    "                    zz = z + dz\n",
    "                    if 0 <= zz < w and fiss_sl[x, zz]:\n",
    "                        covered += 1\n",
    "                        break\n",
    "    return covered, total\n",
    "\n",
    "def strip_nii(name: str) -> str:\n",
    "    return name.replace(\".nii.gz\", \"\").replace(\".nii\", \"\").split(\"_postprocessed\")[0]\n",
    "\n",
    "all_mrns = set()\n",
    "for ftype, fdir in dirs.items():\n",
    "    all_mrns.update(strip_nii(p.name) for p in Path(fdir).rglob(\"*.nii*\"))\n",
    "\n",
    "print(f\"üîç Found {len(all_mrns)} unique MRNs across all fissure predictions\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for mrn in tqdm(sorted(all_mrns), desc=\"Computing all completeness values\"):\n",
    "    print(f\"\\nüìã Processing MRN: {mrn}\")\n",
    "    \n",
    "    lobepath = Path(lobe_dir) / f\"{mrn}.nii.gz\"\n",
    "    if not lobepath.exists():\n",
    "        lobepath = Path(lobe_dir) / f\"{mrn}.nii\"\n",
    "    if not lobepath.exists():\n",
    "        print(f\"   ‚ùå Lobe mask missing for {mrn} - skipped\")\n",
    "        continue\n",
    "\n",
    "    lob = nib.load(lobepath).get_fdata().astype(np.uint8)\n",
    "    entry = {\"MRN\": mrn}\n",
    "    cov_tot_sum = [0, 0]\n",
    "    rul_cov_tot = [0, 0]\n",
    "    \n",
    "    # LOF\n",
    "    fpath = Path(dirs[\"LOF\"]) / f\"{mrn}.nii.gz\"\n",
    "    if not fpath.exists():\n",
    "        fpath = Path(dirs[\"LOF\"]) / f\"{mrn}.nii\"\n",
    "    if not fpath.exists():\n",
    "        entry[\"LOF\"] = np.nan\n",
    "        print(f\"   ‚ùå LOF prediction missing\")\n",
    "    else:\n",
    "        fiss = (nib.load(fpath).get_fdata() > 0).astype(np.uint8)\n",
    "        cov, tot = get_covered_and_total(fiss, lob, *junctions[\"LOF\"])\n",
    "        entry[\"LOF\"] = np.nan if tot == 0 else 100.0 * cov / tot\n",
    "        print(f\"   ‚úÖ LOF: {entry['LOF']:.1f}% ({cov}/{tot})\")\n",
    "\n",
    "    # RHF\n",
    "    fpath = Path(dirs[\"RHF\"]) / f\"{mrn}.nii.gz\"\n",
    "    if not fpath.exists():\n",
    "        fpath = Path(dirs[\"RHF\"]) / f\"{mrn}.nii\"\n",
    "    if not fpath.exists():\n",
    "        entry[\"RHF\"] = np.nan\n",
    "        print(f\"   ‚ùå RHF prediction missing\")\n",
    "    else:\n",
    "        fiss = (nib.load(fpath).get_fdata() > 0).astype(np.uint8)\n",
    "        cov, tot = get_covered_and_total(fiss, lob, *junctions[\"RHF\"])\n",
    "        entry[\"RHF\"] = np.nan if tot == 0 else 100.0 * cov / tot\n",
    "        cov_tot_sum[0] += cov\n",
    "        cov_tot_sum[1] += tot\n",
    "        rul_cov_tot[0] += cov\n",
    "        rul_cov_tot[1] += tot\n",
    "        print(f\"   ‚úÖ RHF: {entry['RHF']:.1f}% ({cov}/{tot})\")\n",
    "\n",
    "    # ROF\n",
    "    fpath = Path(dirs[\"ROF\"]) / f\"{mrn}.nii.gz\"\n",
    "    if not fpath.exists():\n",
    "        fpath = Path(dirs[\"ROF\"]) / f\"{mrn}.nii\"\n",
    "    if not fpath.exists():\n",
    "        entry[\"ROF_combined\"] = np.nan\n",
    "        print(f\"   ‚ùå ROF prediction missing\")\n",
    "    else:\n",
    "        fiss = (nib.load(fpath).get_fdata() > 0).astype(np.uint8)\n",
    "        rof_total_cov = rof_total_tot = 0\n",
    "        cov1, tot1 = get_covered_and_total(fiss, lob, *junctions[\"ROF1\"])\n",
    "        rof_total_cov += cov1\n",
    "        rof_total_tot += tot1\n",
    "        rul_cov_tot[0] += cov1\n",
    "        rul_cov_tot[1] += tot1\n",
    "        print(f\"   üìä ROF1 (1‚Üî3): ({cov1}/{tot1})\")\n",
    "        cov2, tot2 = get_covered_and_total(fiss, lob, *junctions[\"ROF2\"])\n",
    "        rof_total_cov += cov2\n",
    "        rof_total_tot += tot2\n",
    "        print(f\"   üìä ROF2 (2‚Üî3): ({cov2}/{tot2})\")\n",
    "        entry[\"ROF_combined\"] = np.nan if rof_total_tot == 0 else 100.0 * rof_total_cov / rof_total_tot\n",
    "        print(f\"   ‚úÖ ROF Combined: {entry['ROF_combined']:.1f}% ({rof_total_cov}/{rof_total_tot})\")\n",
    "        cov_tot_sum[0] += cov2\n",
    "        cov_tot_sum[1] += tot2\n",
    "\n",
    "    entry[\"RML1\"] = np.nan if cov_tot_sum[1] == 0 else 100.0 * cov_tot_sum[0] / cov_tot_sum[1]\n",
    "    print(f\"   ‚úÖ RML1 (RHF+ROF2): {entry['RML1']:.1f}% ({cov_tot_sum[0]}/{cov_tot_sum[1]})\")\n",
    "\n",
    "    entry[\"RUL\"] = np.nan if rul_cov_tot[1] == 0 else 100.0 * rul_cov_tot[0] / rul_cov_tot[1]\n",
    "    print(f\"   ‚úÖ RUL (RHF+ROF1): {entry['RUL']:.1f}% ({rul_cov_tot[0]}/{rul_cov_tot[1]})\")\n",
    "\n",
    "    records.append(entry)\n",
    "\n",
    "df = pd.DataFrame(records).sort_values(\"MRN\").reset_index(drop=True)\n",
    "df.to_excel(out_xls, index=False)\n",
    "print(f\"\\n‚úÖ Saved to {out_xls}\")\n",
    "print(f\"üìä Processed {len(records)} MRNs total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e0442",
   "metadata": {},
   "source": [
    "## Quality check of the predicted fissures vs lobe borders - Chartis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3fbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, nibabel as nib, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Parameters ===\n",
    "threshold_fissure_far_from_border = 30\n",
    "threshold_multiple_borders = 30\n",
    "\n",
    "# === Paths (Chartis CTs) ===\n",
    "root_dir = r\"------ INSERT PATH HERE ------\"\n",
    "lobes_dir = os.path.join(root_dir, \"pred_folder_lobes134_best25003dEdited\")\n",
    "fissure_dirs = {\n",
    "    \"LOF\": os.path.join(root_dir, \"pred_folder_LOF134_best5000\"),\n",
    "    \"ROF\": os.path.join(root_dir, \"pred_folder_ROF134_best5000\"),\n",
    "    \"RHF\": os.path.join(root_dir, \"pred_folder_RHF134_best5000\"),\n",
    "}\n",
    "out_xls = os.path.join(root_dir, \"fissure_not_amenable_summary_chartis.xlsx\")\n",
    "\n",
    "# === Define fissure border pairs ===\n",
    "fissure_defs = {\n",
    "    \"LOF\": [(4, 5)],\n",
    "    \"ROF\": [(1, 3), (2, 3)],\n",
    "    \"RHF\": [(1, 2)],\n",
    "    \"RUL\": [(1, 2), (1, 3)] \n",
    "}\n",
    "\n",
    "def strip_nii(name): return name.replace(\".nii.gz\", \"\").replace(\".nii\", \"\")\n",
    "\n",
    "lobes_mrns = {strip_nii(f.name) for f in Path(lobes_dir).glob(\"*.nii*\")}\n",
    "fissure_mrns = {\n",
    "    k: {strip_nii(f.name) for f in Path(v).glob(\"*.nii*\")} for k, v in fissure_dirs.items()\n",
    "}\n",
    "common_mrns = lobes_mrns & fissure_mrns[\"ROF\"] & fissure_mrns[\"RHF\"] & fissure_mrns[\"LOF\"]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, mrn in enumerate(sorted(common_mrns), 1):\n",
    "    print(f\"\\nüîÑ [{idx}/{len(common_mrns)}] Processing MRN: {mrn}\")\n",
    "    lobes_path = os.path.join(lobes_dir, f\"{mrn}.nii.gz\")\n",
    "    if not os.path.exists(lobes_path):\n",
    "        lobes_path = os.path.join(lobes_dir, f\"{mrn}.nii\")\n",
    "    lobes = nib.load(lobes_path).get_fdata().astype(np.uint8)\n",
    "\n",
    "    fissures = {\n",
    "        k: (nib.load(os.path.join(d, f\"{mrn}.nii.gz\")).get_fdata() > 0).astype(np.uint8)\n",
    "        for k, d in fissure_dirs.items()\n",
    "    }\n",
    "\n",
    "    H, D, W = lobes.shape\n",
    "    mrn_result = {\"MRN\": mrn}\n",
    "\n",
    "    for fissure_name, border_pairs in fissure_defs.items():\n",
    "        print(f\"   ‚û§ Fissure: {fissure_name}\")\n",
    "        total = 0\n",
    "        not_amenable = 0\n",
    "\n",
    "        for (A, B) in border_pairs:\n",
    "            if fissure_name == \"RUL\":\n",
    "                # Use RHF for (1,2) and ROF for (2,3)\n",
    "                if (A, B) == (1, 2):\n",
    "                    fissure_pred = fissures[\"RHF\"]\n",
    "                elif (A, B) == (1, 3):\n",
    "                    fissure_pred = fissures[\"ROF\"]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected pair for RUL: {A}, {B}\")\n",
    "            else:\n",
    "                fissure_pred = fissures[fissure_name]\n",
    "\n",
    "            for y in range(D):\n",
    "                for x in range(H):\n",
    "                    line = lobes[x, y, :]\n",
    "                    line_pred = fissure_pred[x, y, :]\n",
    "\n",
    "                    if A not in line or B not in line:\n",
    "                        continue\n",
    "                    total += 1\n",
    "\n",
    "                    border_rows = []\n",
    "                    for z in range(W):\n",
    "                        if line[z] == A and np.any(line[max(0, z-1):z+2] == B):\n",
    "                            border_rows.append(z)\n",
    "                        elif line[z] == B and np.any(line[max(0, z-1):z+2] == A):\n",
    "                            border_rows.append(z)\n",
    "\n",
    "                    fissure_rows = np.where(line_pred > 0)[0]\n",
    "\n",
    "                    # Heuristic 1\n",
    "                    if len(fissure_rows) > 0 and len(border_rows) > 0:\n",
    "                        min_dist = min([np.min(np.abs(fissure_rows - b)) for b in border_rows])\n",
    "                        if min_dist > threshold_fissure_far_from_border:\n",
    "                            not_amenable += 1\n",
    "                            continue\n",
    "\n",
    "                    # Heuristic 2\n",
    "                    if len(border_rows) > 1 and (np.max(border_rows) - np.min(border_rows) > threshold_multiple_borders):\n",
    "                        not_amenable += 1\n",
    "                        continue\n",
    "\n",
    "        percent = 100 * not_amenable / total if total else 0\n",
    "        print(f\"     ‚¨ÖÔ∏è {fissure_name}: {not_amenable}/{total} not amenable ({percent:.2f}%)\")\n",
    "\n",
    "        # Store values in spread columns\n",
    "        mrn_result[f\"{fissure_name}_not_amenable\"] = not_amenable\n",
    "        mrn_result[f\"{fissure_name}_total\"] = total\n",
    "        mrn_result[f\"{fissure_name}_percent\"] = round(percent, 2)\n",
    "\n",
    "    all_results.append(mrn_result)\n",
    "\n",
    "# === Save summary ===\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Optional: sort columns\n",
    "fissures = [\"LOF\", \"ROF\", \"RHF\", \"RUL\"]\n",
    "metrics = [\"not_amenable\", \"total\", \"percent\"]\n",
    "ordered_cols = [\"MRN\"] + [f\"{f}_{m}\" for f in fissures for m in metrics]\n",
    "df = df.reindex(columns=ordered_cols)\n",
    "\n",
    "df.to_excel(out_xls, index=False)\n",
    "print(f\"\\n‚úÖ Saved summary to: {out_xls}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53015b2",
   "metadata": {},
   "source": [
    "## Diagnostic accuracy metrics of Model-derived fissure completeness scores for predicting Chartis CV negative status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === Load data ===\n",
    "completeness = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise.xlsx\")\n",
    "chartis_outcome = pd.read_excel(r\"------ INSERT PATH HERE ------\\ChartisList_withFEV1.xlsx\")\n",
    "\n",
    "# === Clean column names ===\n",
    "completeness.columns = completeness.columns.str.strip()\n",
    "chartis_outcome.columns = chartis_outcome.columns.str.strip()\n",
    "\n",
    "# === Merge by MRN ===\n",
    "df = completeness.merge(chartis_outcome, on=\"MRN\", how=\"inner\")\n",
    "df = df.rename(columns={\"ROF_combined\": \"ROF\"})\n",
    "\n",
    "# === Map fissures to Chartis outcome columns ===\n",
    "fissure_to_outcome = {\n",
    "    \"LOF\": \"L\",\n",
    "    \"ROF\": \"RLL1\",\n",
    "    \"RUL\": \"RUL1\"\n",
    "}\n",
    "\n",
    "# === Confusion matrix + metrics at fixed threshold ===\n",
    "threshold = 92\n",
    "\n",
    "for fissure, outcome_col in fissure_to_outcome.items():\n",
    "    df_sub = df[[fissure, outcome_col]].dropna()\n",
    "\n",
    "    y_true = df_sub[outcome_col].values  # 1 = No CV, 0 = CV\n",
    "    y_score = df_sub[fissure].values\n",
    "    y_pred = (y_score >= threshold).astype(int)  # ‚â• threshold ‚Üí predict No CV (1)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "    cm_flipped = cm.T\n",
    "\n",
    "    row_labels = [f\"‚â•{threshold} (No CV)\", f\"<{threshold} (CV)\"]\n",
    "    col_labels = [\"1 (No CV)\", \"0 (CV present)\"]\n",
    "\n",
    "    print(f\"\\n=== {fissure} ‚Äî Confusion Matrix at Threshold {threshold}% ===\")\n",
    "    print(\"Confusion Matrix (rows = predicted, cols = actual):\")\n",
    "    print(\" \" * 20 + \"\".join([f\"{label:>20}\" for label in col_labels]))\n",
    "    for j, row in enumerate(cm_flipped):\n",
    "        print(f\"{row_labels[j]:<20}\" + \"\".join([f\"{val:>20}\" for val in row]))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "    specificity = tn / (tn + fp) if (tn + fp) else np.nan\n",
    "    ppv = tp / (tp + fp) if (tp + fp) else np.nan  # Precision\n",
    "    npv = tn / (tn + fn) if (tn + fn) else np.nan\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Sensitivity (No CV):      {sensitivity:.2f}\")\n",
    "    print(f\"Specificity (CV):         {specificity:.2f}\")\n",
    "    print(f\"PPV (Predicted No CV):    {ppv:.2f}\")\n",
    "    print(f\"NPV (Predicted CV):       {npv:.2f}\")\n",
    "    print(f\"Accuracy:                 {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81281079",
   "metadata": {},
   "source": [
    "## Diagnostic accuracy metrics of StratX-derived fissure completeness scores for predicting Chartis CV negative status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6672ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === Load data ===\n",
    "stratx_file = r\"------ INSERT PATH HERE ------\\StratX_List_2.xlsx\"\n",
    "chartis_file = r\"------ INSERT PATH HERE ------\\ChartisList_withFEV1.xlsx\"\n",
    "\n",
    "stratx = pd.read_excel(stratx_file)\n",
    "chartis = pd.read_excel(chartis_file)\n",
    "\n",
    "# === Clean column names and MRNs ===\n",
    "stratx.columns = stratx.columns.str.strip()\n",
    "chartis.columns = chartis.columns.str.strip()\n",
    "stratx[\"MRN\"] = stratx[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "chartis[\"MRN\"] = chartis[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "\n",
    "# === Merge on MRN ===\n",
    "df = stratx.merge(chartis, on=\"MRN\", how=\"inner\")\n",
    "\n",
    "# === Fissure mapping ===\n",
    "fissure_to_outcome = {\n",
    "    \"LUL\": \"L\",\n",
    "    \"RLL\": \"RLL1\",\n",
    "    \"RUL\": \"RUL1\"\n",
    "}\n",
    "\n",
    "# === Confusion matrix + metrics at threshold ===\n",
    "threshold = 95\n",
    "\n",
    "for stratx_col, chartis_col in fissure_to_outcome.items():\n",
    "    df_sub = df[[stratx_col, chartis_col]].dropna()\n",
    "\n",
    "    y_true = df_sub[chartis_col].astype(int).values  # 1 = No CV, 0 = CV\n",
    "    y_score = df_sub[stratx_col].astype(float).values\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "    cm_flipped = cm.T\n",
    "\n",
    "    row_labels = [f\"‚â•{threshold} (No CV)\", f\"<{threshold} (CV)\"]\n",
    "    col_labels = [\"1 (No CV)\", \"0 (CV present)\"]\n",
    "\n",
    "    print(f\"\\n=== {stratx_col} ‚Äî Confusion Matrix at Threshold {threshold}% ===\")\n",
    "    print(\"Confusion Matrix (rows = predicted, cols = actual):\")\n",
    "    print(\" \" * 20 + \"\".join([f\"{label:>20}\" for label in col_labels]))\n",
    "    for j, row in enumerate(cm_flipped):\n",
    "        print(f\"{row_labels[j]:<20}\" + \"\".join([f\"{val:>20}\" for val in row]))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "    specificity = tn / (tn + fp) if (tn + fp) else np.nan\n",
    "    ppv = tp / (tp + fp) if (tp + fp) else np.nan\n",
    "    npv = tn / (tn + fn) if (tn + fn) else np.nan\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Sensitivity (No CV):      {sensitivity:.2f}\")\n",
    "    print(f\"Specificity (CV):         {specificity:.2f}\")\n",
    "    print(f\"PPV (Predicted No CV):    {ppv:.2f}\")\n",
    "    print(f\"NPV (Predicted CV):       {npv:.2f}\")\n",
    "    print(f\"Accuracy:                 {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bacaf2",
   "metadata": {},
   "source": [
    "## ROC of Model and StratX derived fissure completeness scores to predict negative collaternal ventilation status on Chartis (all cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# === Load data ===\n",
    "completeness = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise.xlsx\")\n",
    "chartis_outcome = pd.read_excel(r\"------ INSERT PATH HERE ------\\ChartisList_withFEV1.xlsx\")\n",
    "stratx = pd.read_excel(r\"------ INSERT PATH HERE ------\\StratX_List_2.xlsx\")\n",
    "\n",
    "# === Clean column names and MRNs ===\n",
    "completeness.columns = completeness.columns.str.strip()\n",
    "chartis_outcome.columns = chartis_outcome.columns.str.strip()\n",
    "stratx.columns = stratx.columns.str.strip()\n",
    "completeness[\"MRN\"] = completeness[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "chartis_outcome[\"MRN\"] = chartis_outcome[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "stratx[\"MRN\"] = stratx[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "completeness = completeness.rename(columns={\"ROF_combined\": \"ROF\"})\n",
    "\n",
    "# === Merge datasets ===\n",
    "df_model = completeness.merge(chartis_outcome, on=\"MRN\", how=\"inner\")\n",
    "df_stratx = stratx.merge(chartis_outcome, on=\"MRN\", how=\"inner\")\n",
    "\n",
    "# === Fissure-to-outcome mapping ===\n",
    "fissure_to_outcome_model = {\n",
    "    \"LOF\": \"L\",\n",
    "    \"ROF\": \"RLL1\",\n",
    "    \"RUL\": \"RUL1\"\n",
    "}\n",
    "fissure_to_outcome_stratx = {\n",
    "    \"LUL\": \"L\",\n",
    "    \"RLL\": \"RLL1\",\n",
    "    \"RUL\": \"RUL1\"\n",
    "}\n",
    "fissure_display_names = [\n",
    "    \"Left oblique fissure\",\n",
    "    \"Right oblique fissure\",\n",
    "    \"Fissures around right upper lobe\"\n",
    "]\n",
    "\n",
    "# === Bootstrap ROC with CI function ===\n",
    "def bootstrap_roc_ci(y_true, y_score, n_bootstraps=1000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    tpr_list, aucs = [], []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_score), len(y_score))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        fpr, tpr, _ = roc_curve(y_true[indices], y_score[indices])\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "        tpr_interp = np.interp(base_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tpr_list.append(tpr_interp)\n",
    "    tpr_array = np.array(tpr_list)\n",
    "    mean_tpr = np.mean(tpr_array, axis=0)\n",
    "    std_tpr = np.std(tpr_array, axis=0)\n",
    "    tpr_upper = np.minimum(mean_tpr + 1.96 * std_tpr, 1)\n",
    "    tpr_lower = np.maximum(mean_tpr - 1.96 * std_tpr, 0)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    auc_ci_lower = np.percentile(aucs, 2.5)\n",
    "    auc_ci_upper = np.percentile(aucs, 97.5)\n",
    "    return base_fpr, mean_tpr, tpr_lower, tpr_upper, mean_auc, auc_ci_lower, auc_ci_upper\n",
    "\n",
    "# === Create figure with proper spacing ===\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# === Top row: Model-derived scores ===\n",
    "top_labels = ['A', 'B', 'C']\n",
    "for i, (fissure, outcome_col) in enumerate(fissure_to_outcome_model.items()):\n",
    "    ax = axes[0, i]\n",
    "    df_sub = df_model[[fissure, outcome_col]].dropna()\n",
    "    y_true = df_sub[outcome_col].astype(int).values\n",
    "    y_score = df_sub[fissure].astype(float).values\n",
    "    fpr, mean_tpr, lower_tpr, upper_tpr, auc_mean, auc_lo, auc_hi = bootstrap_roc_ci(y_true, y_score)\n",
    "\n",
    "    ax.plot(fpr, mean_tpr, label=f\"AUC = {auc_mean:.2f} (95% CI: {auc_lo:.2f}‚Äì{auc_hi:.2f})\", lw=2)\n",
    "    ax.fill_between(fpr, lower_tpr, upper_tpr, color='b', alpha=0.2, label=\"95% CI\")\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    ax.set_title(f\"{top_labels[i]}. {fissure_display_names[i]}\", fontsize=12)\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "# === Bottom row: StratX-derived scores ===\n",
    "bottom_labels = ['D', 'E', 'F']\n",
    "for i, (fissure, outcome_col) in enumerate(fissure_to_outcome_stratx.items()):\n",
    "    ax = axes[1, i]\n",
    "    df_sub = df_stratx[[fissure, outcome_col]].dropna()\n",
    "    y_true = df_sub[outcome_col].astype(int).values\n",
    "    y_score = df_sub[fissure].astype(float).values\n",
    "    fpr, mean_tpr, lower_tpr, upper_tpr, auc_mean, auc_lo, auc_hi = bootstrap_roc_ci(y_true, y_score)\n",
    "\n",
    "    ax.plot(fpr, mean_tpr, label=f\"AUC = {auc_mean:.2f} (95% CI: {auc_lo:.2f}‚Äì{auc_hi:.2f})\", lw=2)\n",
    "    ax.fill_between(fpr, lower_tpr, upper_tpr, color='b', alpha=0.2, label=\"95% CI\")\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    ax.set_title(f\"{bottom_labels[i]}. {fissure_display_names[i]}\", fontsize=12)\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "# === Apply tight_layout first, then add section titles ===\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Add section titles with proper spacing ===\n",
    "fig.text(0.5, 0.95, \"Model-derived fissure completeness scores\", ha='center', fontsize=15, weight='bold')\n",
    "fig.text(0.5, 0.48, \"StratX-derived fissure completeness scores\", ha='center', fontsize=15, weight='bold')\n",
    "\n",
    "# === Adjust subplot positions to make room for titles ===\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, hspace=0.4)\n",
    "\n",
    "plt.savefig(r\"------ INSERT PATH HERE ------\\Figures\\Figure5.png\", dpi=300, bbox_inches='tight')  # Save at 300 DPI\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4af87",
   "metadata": {},
   "source": [
    "## Comparing AUROC of Model and StratX derived fissure completeness scores to predict negative collaternal ventialtion status on Chartis (common in both datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe86c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use established DeLong test from MLstatkit\n",
    "try:\n",
    "    from MLstatkit.stats import Delong_test\n",
    "    HAS_MLSTATKIT = True\n",
    "    print(\"Using MLstatkit DeLong test implementation\")\n",
    "except ImportError:\n",
    "    HAS_MLSTATKIT = False\n",
    "    print(\"MLstatkit not available. Install with: pip install MLstatkit\")\n",
    "    print(\"Using fallback method...\")\n",
    "\n",
    "def delong_roc_test(y_true, y_prob1, y_prob2):\n",
    "    \"\"\"\n",
    "    DeLong test using established MLstatkit library\n",
    "    \"\"\"\n",
    "    if HAS_MLSTATKIT:\n",
    "        try:\n",
    "            z_score, p_value = Delong_test(y_true, y_prob1, y_prob2)\n",
    "            return z_score, p_value\n",
    "        except Exception as e:\n",
    "            print(f\"MLstatkit DeLong test failed: {str(e)}\")\n",
    "            return np.nan, np.nan\n",
    "    else:\n",
    "        # Fallback to simple difference test if MLstatkit not available\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        try:\n",
    "            auc1 = roc_auc_score(y_true, y_prob1)\n",
    "            auc2 = roc_auc_score(y_true, y_prob2)\n",
    "            diff = auc1 - auc2\n",
    "            # Very simple approximation - not a proper DeLong test\n",
    "            z_stat = diff / 0.05  # Rough approximation\n",
    "            p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "            return z_stat, p_value\n",
    "        except:\n",
    "            return np.nan, np.nan\n",
    "\n",
    "# === Load and prepare data ===\n",
    "completeness = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise.xlsx\")\n",
    "chartis_outcome = pd.read_excel(r\"------ INSERT PATH HERE ------\\ChartisList_withFEV1.xlsx\")\n",
    "stratx = pd.read_excel(r\"------ INSERT PATH HERE ------\\StratX_List_2.xlsx\")\n",
    "\n",
    "# === Clean data ===\n",
    "completeness.columns = completeness.columns.str.strip()\n",
    "chartis_outcome.columns = chartis_outcome.columns.str.strip()\n",
    "stratx.columns = stratx.columns.str.strip()\n",
    "completeness[\"MRN\"] = completeness[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "chartis_outcome[\"MRN\"] = chartis_outcome[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "stratx[\"MRN\"] = stratx[\"MRN\"].astype(str).str.strip().str.replace(\".0\", \"\", regex=False)\n",
    "completeness = completeness.rename(columns={\"ROF_combined\": \"ROF\"})\n",
    "\n",
    "# === Merge datasets ===\n",
    "df_model = completeness.merge(chartis_outcome, on=\"MRN\", how=\"inner\")\n",
    "df_stratx = stratx.merge(chartis_outcome, on=\"MRN\", how=\"inner\")\n",
    "\n",
    "# === Fissure mappings ===\n",
    "model_mappings = [(\"LOF\", \"L\"), (\"ROF\", \"RLL1\"), (\"RUL\", \"RUL1\")]\n",
    "stratx_mappings = [(\"LUL\", \"L\"), (\"RLL\", \"RLL1\"), (\"RUL\", \"RUL1\")]\n",
    "fissure_names = [\"Left Oblique Fissure\", \"Right Oblique Fissure\", \"Right Upper Lobe Fissures\"]\n",
    "\n",
    "# === Bootstrap AUROC function ===\n",
    "def bootstrap_auroc(y_true, y_score, n_bootstraps=2000, seed=42):\n",
    "    \"\"\"Calculate AUROC with bootstrap confidence intervals\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    aucs = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_score), len(y_score))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        fpr, tpr, _ = roc_curve(y_true[indices], y_score[indices])\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    \n",
    "    aucs = np.array(aucs)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    ci_lower = np.percentile(aucs, 2.5)\n",
    "    ci_upper = np.percentile(aucs, 97.5)\n",
    "    \n",
    "    return mean_auc, ci_lower, ci_upper, aucs\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMBINED AUROC ANALYSIS: ALL FISSURES TOGETHER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# === Collect all paired observations across all fissures ===\n",
    "all_y_true_model = []\n",
    "all_y_score_model = []\n",
    "all_y_true_stratx = []\n",
    "all_y_score_stratx = []\n",
    "all_patient_info = []\n",
    "\n",
    "total_paired_observations = 0\n",
    "\n",
    "for i in range(3):\n",
    "    model_fissure, model_outcome = model_mappings[i]\n",
    "    stratx_fissure, stratx_outcome = stratx_mappings[i]\n",
    "    fissure_name = fissure_names[i]\n",
    "    \n",
    "    # Prepare data for merging\n",
    "    df_model_temp = df_model[[model_fissure, model_outcome, 'MRN']].dropna().copy()\n",
    "    df_stratx_temp = df_stratx[[stratx_fissure, stratx_outcome, 'MRN']].dropna().copy()\n",
    "    \n",
    "    # Rename columns to avoid conflicts\n",
    "    df_model_temp = df_model_temp.rename(columns={\n",
    "        model_fissure: f'{model_fissure}_model_score',\n",
    "        model_outcome: f'{model_outcome}_model_outcome'\n",
    "    })\n",
    "    df_stratx_temp = df_stratx_temp.rename(columns={\n",
    "        stratx_fissure: f'{stratx_fissure}_stratx_score', \n",
    "        stratx_outcome: f'{stratx_outcome}_stratx_outcome'\n",
    "    })\n",
    "    \n",
    "    # Merge for paired comparison\n",
    "    df_paired = df_model_temp.merge(df_stratx_temp, on='MRN')\n",
    "    \n",
    "    if len(df_paired) > 0:\n",
    "        # Extract data\n",
    "        y_true_model = df_paired[f'{model_outcome}_model_outcome'].astype(int).values\n",
    "        y_score_model = df_paired[f'{model_fissure}_model_score'].astype(float).values\n",
    "        y_true_stratx = df_paired[f'{stratx_outcome}_stratx_outcome'].astype(int).values\n",
    "        y_score_stratx = df_paired[f'{stratx_fissure}_stratx_score'].astype(float).values\n",
    "        \n",
    "        # Add to combined lists\n",
    "        all_y_true_model.extend(y_true_model)\n",
    "        all_y_score_model.extend(y_score_model)\n",
    "        all_y_true_stratx.extend(y_true_stratx)\n",
    "        all_y_score_stratx.extend(y_score_stratx)\n",
    "        \n",
    "        # Track patient info\n",
    "        patient_info = [(mrn, fissure_name) for mrn in df_paired['MRN']]\n",
    "        all_patient_info.extend(patient_info)\n",
    "        \n",
    "        total_paired_observations += len(df_paired)\n",
    "        print(f\"{fissure_name}: {len(df_paired)} paired observations\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_y_true_model = np.array(all_y_true_model)\n",
    "all_y_score_model = np.array(all_y_score_model)\n",
    "all_y_true_stratx = np.array(all_y_true_stratx)\n",
    "all_y_score_stratx = np.array(all_y_score_stratx)\n",
    "\n",
    "print(f\"\\nTotal combined observations: {total_paired_observations}\")\n",
    "print(f\"Positive outcomes: {np.sum(all_y_true_model)} / {len(all_y_true_model)} ({100*np.mean(all_y_true_model):.1f}%)\")\n",
    "\n",
    "# === Calculate combined AUROCs ===\n",
    "print(f\"\\nCombined AUROC Analysis:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Model-derived combined AUROC\n",
    "auc_model_combined, ci_low_model, ci_high_model, aucs_model = bootstrap_auroc(\n",
    "    all_y_true_model, all_y_score_model\n",
    ")\n",
    "\n",
    "# StratX-derived combined AUROC  \n",
    "auc_stratx_combined, ci_low_stratx, ci_high_stratx, aucs_stratx = bootstrap_auroc(\n",
    "    all_y_true_stratx, all_y_score_stratx\n",
    ")\n",
    "\n",
    "print(f\"Model-derived AUROC:  {auc_model_combined:.2f} (95% CI: {ci_low_model:.2f}‚Äì{ci_high_model:.2f})\")\n",
    "print(f\"StratX-derived AUROC: {auc_stratx_combined:.2f} (95% CI: {ci_low_stratx:.2f}‚Äì{ci_high_stratx:.2f})\")\n",
    "print(f\"Difference (Model - StratX): {auc_model_combined - auc_stratx_combined:.2f}\")\n",
    "\n",
    "# === Statistical comparison ===\n",
    "print(f\"\\nStatistical Comparison:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Statistical test using established DeLong test from MLstatkit\n",
    "try:\n",
    "    z_stat, p_delong = delong_roc_test(all_y_true_model, all_y_score_model, all_y_score_stratx)\n",
    "    print(f\"DeLong test: z={z_stat:.2f}, p={p_delong:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"DeLong test failed: {str(e)}\")\n",
    "    p_delong = np.nan\n",
    "\n",
    "# Bootstrap difference test\n",
    "auc_differences = aucs_model - aucs_stratx\n",
    "p_bootstrap = 2 * min(np.mean(auc_differences >= 0), np.mean(auc_differences <= 0))\n",
    "print(f\"Bootstrap test: p={p_bootstrap:.4f}\")\n",
    "print(f\"Mean difference: {np.mean(auc_differences):.2f} ¬± {np.std(auc_differences):.2f}\")\n",
    "\n",
    "# Statistical interpretation\n",
    "if not np.isnan(p_delong):\n",
    "    if p_delong < 0.001:\n",
    "        sig_level = \"*** (p<0.001)\"\n",
    "    elif p_delong < 0.01:\n",
    "        sig_level = \"** (p<0.01)\"\n",
    "    elif p_delong < 0.05:\n",
    "        sig_level = \"* (p<0.05)\"\n",
    "    else:\n",
    "        sig_level = \"ns (not significant)\"\n",
    "    print(f\"Significance: {sig_level}\")\n",
    "\n",
    "# === Create 2x2 subplot layout ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Bootstrap for confidence intervals on ROC curves\n",
    "def bootstrap_roc_curves(y_true, y_score, n_bootstraps=1000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    tpr_list = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_score), len(y_score))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        fpr, tpr, _ = roc_curve(y_true[indices], y_score[indices])\n",
    "        tpr_interp = np.interp(base_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tpr_list.append(tpr_interp)\n",
    "    \n",
    "    tpr_array = np.array(tpr_list)\n",
    "    mean_tpr = np.mean(tpr_array, axis=0)\n",
    "    tpr_lower = np.percentile(tpr_array, 2.5, axis=0)\n",
    "    tpr_upper = np.percentile(tpr_array, 97.5, axis=0)\n",
    "    \n",
    "    return base_fpr, mean_tpr, tpr_lower, tpr_upper\n",
    "\n",
    "# Subplot labels\n",
    "subplot_labels = ['A', 'B', 'C', 'D']\n",
    "\n",
    "# === First three subplots: Individual fissures ===\n",
    "individual_results = []\n",
    "\n",
    "for i in range(3):\n",
    "    ax = axes[i]\n",
    "    model_fissure, model_outcome = model_mappings[i]\n",
    "    stratx_fissure, stratx_outcome = stratx_mappings[i]\n",
    "    fissure_name = fissure_names[i]\n",
    "    \n",
    "    # Prepare data for merging\n",
    "    df_model_temp = df_model[[model_fissure, model_outcome, 'MRN']].dropna().copy()\n",
    "    df_stratx_temp = df_stratx[[stratx_fissure, stratx_outcome, 'MRN']].dropna().copy()\n",
    "    \n",
    "    # Rename columns to avoid conflicts\n",
    "    df_model_temp = df_model_temp.rename(columns={\n",
    "        model_fissure: f'{model_fissure}_model_score',\n",
    "        model_outcome: f'{model_outcome}_model_outcome'\n",
    "    })\n",
    "    df_stratx_temp = df_stratx_temp.rename(columns={\n",
    "        stratx_fissure: f'{stratx_fissure}_stratx_score', \n",
    "        stratx_outcome: f'{stratx_outcome}_stratx_outcome'\n",
    "    })\n",
    "    \n",
    "    # Merge for paired comparison\n",
    "    df_paired = df_model_temp.merge(df_stratx_temp, on='MRN')\n",
    "    \n",
    "    if len(df_paired) > 0:\n",
    "        # Extract data\n",
    "        y_true = df_paired[f'{model_outcome}_model_outcome'].astype(int).values\n",
    "        y_score_model = df_paired[f'{model_fissure}_model_score'].astype(float).values\n",
    "        y_score_stratx = df_paired[f'{stratx_fissure}_stratx_score'].astype(float).values\n",
    "        \n",
    "        # Calculate individual AUROCs\n",
    "        auc_model_ind, ci_low_model_ind, ci_high_model_ind, _ = bootstrap_auroc(y_true, y_score_model)\n",
    "        auc_stratx_ind, ci_low_stratx_ind, ci_high_stratx_ind, _ = bootstrap_auroc(y_true, y_score_stratx)\n",
    "        \n",
    "        # Calculate ROC curves\n",
    "        fpr_model, tpr_model, _ = roc_curve(y_true, y_score_model)\n",
    "        fpr_stratx, tpr_stratx, _ = roc_curve(y_true, y_score_stratx)\n",
    "        \n",
    "        # Get confidence intervals for ROC curves\n",
    "        fpr_model_ci, tpr_model_ci, tpr_model_lower, tpr_model_upper = bootstrap_roc_curves(y_true, y_score_model)\n",
    "        fpr_stratx_ci, tpr_stratx_ci, tpr_stratx_lower, tpr_stratx_upper = bootstrap_roc_curves(y_true, y_score_stratx)\n",
    "        \n",
    "        # Plot ROC curves with confidence intervals\n",
    "        ax.plot(fpr_model, tpr_model, 'b-', lw=2, \n",
    "                label=f'Model: {auc_model_ind:.2f} ({ci_low_model_ind:.2f}‚Äì{ci_high_model_ind:.2f})')\n",
    "        ax.fill_between(fpr_model_ci, tpr_model_lower, tpr_model_upper, \n",
    "                        color='blue', alpha=0.2)\n",
    "        \n",
    "        ax.plot(fpr_stratx, tpr_stratx, 'r-', lw=2, \n",
    "                label=f'StratX: {auc_stratx_ind:.2f} ({ci_low_stratx_ind:.2f}‚Äì{ci_high_stratx_ind:.2f})')\n",
    "        ax.fill_between(fpr_stratx_ci, tpr_stratx_lower, tpr_stratx_upper, \n",
    "                        color='red', alpha=0.2)\n",
    "        \n",
    "        ax.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "        \n",
    "        # Statistical test using established DeLong test from MLstatkit\n",
    "        try:\n",
    "            z_stat_ind, p_value_ind = delong_roc_test(y_true, y_score_model, y_score_stratx)\n",
    "            print(f\"  {fissure_name}: DeLong z={z_stat_ind:.3f}, p={p_value_ind:.4f}\")\n",
    "        except:\n",
    "            z_stat_ind, p_value_ind = np.nan, np.nan\n",
    "            print(f\"  {fissure_name}: DeLong test failed\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_title(f'{subplot_labels[i]}. {fissure_name} (n={len(df_paired)})', fontsize=12, weight='bold')\n",
    "        ax.set_xlabel('False Positive Rate', fontsize=10)\n",
    "        ax.set_ylabel('True Positive Rate', fontsize=10)\n",
    "        ax.legend(fontsize=9, loc='lower right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add p-value - use the individual p-value for this subplot\n",
    "        if not np.isnan(p_value_ind):\n",
    "            ax.text(0.05, 0.95, f'p = {p_value_ind:.3f}', \n",
    "                    fontsize=9, bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightgray\"),\n",
    "                    transform=ax.transAxes, verticalalignment='top')\n",
    "        \n",
    "        # Store results with individual p-value\n",
    "        individual_results.append({\n",
    "            'fissure': fissure_name,\n",
    "            'n_paired': len(df_paired),\n",
    "            'model_auc': auc_model_ind,\n",
    "            'stratx_auc': auc_stratx_ind,\n",
    "            'p_value': p_value_ind  # Use individual p-value\n",
    "        })\n",
    "\n",
    "# === Fourth subplot: Combined analysis ===\n",
    "ax = axes[3]\n",
    "\n",
    "# Calculate combined ROC curves (using the already calculated data from above)\n",
    "fpr_model_combined, tpr_model_combined, _ = roc_curve(all_y_true_model, all_y_score_model)\n",
    "fpr_stratx_combined, tpr_stratx_combined, _ = roc_curve(all_y_true_stratx, all_y_score_stratx)\n",
    "\n",
    "# Get confidence intervals for combined ROC curves\n",
    "fpr_model_ci_comb, tpr_model_ci_comb, tpr_model_lower_comb, tpr_model_upper_comb = bootstrap_roc_curves(\n",
    "    all_y_true_model, all_y_score_model)\n",
    "fpr_stratx_ci_comb, tpr_stratx_ci_comb, tpr_stratx_lower_comb, tpr_stratx_upper_comb = bootstrap_roc_curves(\n",
    "    all_y_true_stratx, all_y_score_stratx)\n",
    "\n",
    "# Plot combined ROC curves with confidence intervals\n",
    "ax.plot(fpr_model_combined, tpr_model_combined, 'b-', lw=2, \n",
    "        label=f'Model: {auc_model_combined:.2f} ({ci_low_model:.2f}‚Äì{ci_high_model:.2f})')\n",
    "ax.fill_between(fpr_model_ci_comb, tpr_model_lower_comb, tpr_model_upper_comb, \n",
    "                color='blue', alpha=0.2)\n",
    "\n",
    "ax.plot(fpr_stratx_combined, tpr_stratx_combined, 'r-', lw=2, \n",
    "        label=f'StratX: {auc_stratx_combined:.2f} ({ci_low_stratx:.2f}‚Äì{ci_high_stratx:.2f})')\n",
    "ax.fill_between(fpr_stratx_ci_comb, tpr_stratx_lower_comb, tpr_stratx_upper_comb, \n",
    "                color='red', alpha=0.2)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "\n",
    "ax.set_title(f'{subplot_labels[3]}. Combined: All Fissures (n=83)', fontsize=12, weight='bold')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=10)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=10)\n",
    "ax.legend(fontsize=9, loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add combined p-value\n",
    "if not np.isnan(p_delong):\n",
    "    ax.text(0.05, 0.95, f'p = {p_delong:.3f}', \n",
    "            fontsize=9, bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightgray\"),\n",
    "            transform=ax.transAxes, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"------ INSERT PATH HERE ------\\Figures\\Figure6.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY:\")\n",
    "print(f\"Combined analysis shows {'significant' if p_delong < 0.05 else 'no significant'} difference\")\n",
    "print(f\"between Model-derived (AUC={auc_model_combined:.2f}) and StratX-derived (AUC={auc_stratx_combined:.2f})\")\n",
    "print(f\"fissure completeness scores across all three fissure types.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
