{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cce8023",
   "metadata": {},
   "source": [
    "### 3D island postprocessing of Strat X lobe segmentation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import label, binary_dilation\n",
    "\n",
    "# === Directories ===\n",
    "input_dir = r\"------ INSERT PATH HERE ------\"\n",
    "output_dir = os.path.join(os.path.dirname(input_dir), \"pred_folder_lobes134_best25003dEdited_2500\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Function to assign an isolated component to the neighboring label with largest contact ===\n",
    "def reassign_to_largest_border_component(island_mask, full_mask):\n",
    "    dilated = binary_dilation(island_mask, iterations=1)\n",
    "    border_voxels = dilated & (full_mask > 0) & (~island_mask)\n",
    "    neighbor_labels, counts = np.unique(full_mask[border_voxels], return_counts=True)\n",
    "    if len(counts) == 0:\n",
    "        return 0  # assign to background\n",
    "    return neighbor_labels[np.argmax(counts)]\n",
    "\n",
    "# === Main postprocessing function ===\n",
    "def remove_isolated_components(filepath, output_dir):\n",
    "    img = nib.load(filepath)\n",
    "    data = img.get_fdata().astype(np.uint8)\n",
    "    new_data = np.zeros_like(data)\n",
    "\n",
    "    label_changes = {}\n",
    "    to_background_volumes = {}\n",
    "    total_voxels_changed = 0\n",
    "\n",
    "    for label_id in range(1, 6):  # Labels 1 to 5\n",
    "        binary = (data == label_id)\n",
    "        if not np.any(binary):\n",
    "            continue\n",
    "        labeled_cc, num = label(binary)\n",
    "        sizes = np.bincount(labeled_cc.ravel())\n",
    "        sizes[0] = 0\n",
    "        if len(sizes) == 1:\n",
    "            new_data[labeled_cc == 1] = label_id\n",
    "            continue\n",
    "        largest_cc = np.argmax(sizes)\n",
    "        new_data[labeled_cc == largest_cc] = label_id\n",
    "        for i in range(1, num + 1):\n",
    "            if i == largest_cc:\n",
    "                continue\n",
    "            island_mask = (labeled_cc == i)\n",
    "            new_label = reassign_to_largest_border_component(island_mask, data)\n",
    "            vol = np.sum(island_mask)\n",
    "            total_voxels_changed += vol\n",
    "            if new_label == 0:\n",
    "                to_background_volumes[filepath.name] = to_background_volumes.get(filepath.name, 0) + vol\n",
    "            else:\n",
    "                key = (filepath.name, label_id, new_label)\n",
    "                label_changes[key] = label_changes.get(key, 0) + vol\n",
    "            new_data[island_mask] = new_label\n",
    "\n",
    "    out_path = os.path.join(output_dir, os.path.basename(filepath))\n",
    "    nib.save(nib.Nifti1Image(new_data, img.affine, img.header), out_path)\n",
    "    return label_changes, to_background_volumes, total_voxels_changed\n",
    "\n",
    "# === Process all files ===\n",
    "all_files = list(Path(input_dir).glob(\"*.nii.gz\"))\n",
    "total_label_changes = {}\n",
    "total_bg_changes = {}\n",
    "\n",
    "for f in all_files:\n",
    "    print(f\"ğŸ”„ Processing {f.name} ...\")\n",
    "    label_chg, bg_chg, total_changed = remove_isolated_components(f, output_dir)\n",
    "    for k, v in label_chg.items():\n",
    "        total_label_changes[k] = total_label_changes.get(k, 0) + v\n",
    "    for k, v in bg_chg.items():\n",
    "        total_bg_changes[k] = total_bg_changes.get(k, 0) + v\n",
    "    print(f\"âœ… Done {f.name} â€” total voxels reassigned: {total_changed}\")\n",
    "\n",
    "# === Summary ===\n",
    "print(\"\\nğŸ” Top 5 conversions from one label to another:\")\n",
    "for (name, from_label, to_label), vol in sorted(total_label_changes.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{name}: {vol} voxels from label {from_label} â†’ {to_label}\")\n",
    "\n",
    "print(\"\\nğŸ” Top 5 conversions from label to background:\")\n",
    "for name, vol in sorted(total_bg_changes.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{name}: {vol} voxels converted to background\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87398c",
   "metadata": {},
   "source": [
    "## Calculating the fissure completeness of StratX dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, nibabel as nib, pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â”€â”€ Input paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "root_dir = r\"------ INSERT PATH HERE ------\"\n",
    "pred_dir = os.path.join(root_dir, \"Pred\")\n",
    "\n",
    "dirs = {\n",
    "    \"LOF\": os.path.join(pred_dir, \"pred_folder_LOF134_best5000\"),\n",
    "    \"ROF\": os.path.join(pred_dir, \"pred_folder_ROF134_best5000\"),\n",
    "    \"RHF\": os.path.join(pred_dir, \"pred_folder_RHF134_best5000\"),\n",
    "}\n",
    "lobe_dir = os.path.join(pred_dir, \"pred_folder_lobes134_best25003dEdited_2500\")\n",
    "out_xls  = os.path.join(pred_dir, \"fissure_completeness_all_columnwise.xlsx\")\n",
    "\n",
    "# â”€â”€ Algorithm params â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "z_window, max_search, max_gap = 5, 4, 5\n",
    "junctions = {\n",
    "    \"LOF\": (4, 5),\n",
    "    \"RHF\": (1, 2),\n",
    "    \"ROF1\": (1, 3),\n",
    "    \"ROF2\": (2, 3)\n",
    "}\n",
    "\n",
    "def get_covered_and_total(fiss, lob, A, B):\n",
    "    h, n_slices, w = lob.shape\n",
    "    covered = total = 0\n",
    "    for y in range(n_slices):\n",
    "        lob_sl, fiss_sl = lob[:, y, :], fiss[:, y, :]\n",
    "        prevA = prevB = None\n",
    "        for x in range(h):\n",
    "            col = lob_sl[x, :]\n",
    "            if A not in col or B not in col:\n",
    "                continue\n",
    "            candA = [z for z in np.where(col == A)[0] if np.any(col[max(z-max_search,0): z+max_search+1] == B)]\n",
    "            candB = [z for z in np.where(col == B)[0] if np.any(col[max(z-max_search,0): z+max_search+1] == A)]\n",
    "            border_z = []\n",
    "            if candA:\n",
    "                zA = min(candA)\n",
    "                if prevA is None or abs(zA-prevA) <= max_gap:\n",
    "                    border_z.append(zA); prevA = zA\n",
    "                else: prevA = None\n",
    "            if candB:\n",
    "                zB = max(candB)\n",
    "                if prevB is None or abs(zB-prevB) <= max_gap:\n",
    "                    border_z.append(zB); prevB = zB\n",
    "                else: prevB = None\n",
    "            for z in border_z:\n",
    "                total += 1\n",
    "                for dz in range(-z_window, z_window+1):\n",
    "                    zz = z + dz\n",
    "                    if 0 <= zz < w and fiss_sl[x, zz]:\n",
    "                        covered += 1\n",
    "                        break\n",
    "    return covered, total\n",
    "\n",
    "def strip_nii(name: str) -> str:\n",
    "    return name.replace(\".nii.gz\", \"\").replace(\".nii\", \"\").split(\"_postprocessed\")[0]\n",
    "\n",
    "all_mrns = set()\n",
    "for ftype, fdir in dirs.items():\n",
    "    all_mrns.update(strip_nii(p.name) for p in Path(fdir).rglob(\"*.nii*\"))\n",
    "\n",
    "print(f\"ğŸ” Found {len(all_mrns)} unique MRNs across all fissure predictions\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for mrn in tqdm(sorted(all_mrns), desc=\"Computing all completeness values\"):\n",
    "    print(f\"\\nğŸ“‹ Processing MRN: {mrn}\")\n",
    "    \n",
    "    lobepath = Path(lobe_dir) / f\"{mrn}.nii.gz\"\n",
    "    if not lobepath.exists():\n",
    "        lobepath = Path(lobe_dir) / f\"{mrn}.nii\"\n",
    "    if not lobepath.exists():\n",
    "        print(f\"   âŒ Lobe mask missing for {mrn} - skipped\")\n",
    "        continue\n",
    "\n",
    "    lob = nib.load(lobepath).get_fdata().astype(np.uint8)\n",
    "    entry = {\"MRN\": mrn}\n",
    "    cov_tot_sum = [0, 0]\n",
    "    rul_cov_tot = [0, 0]\n",
    "    \n",
    "    # LOF\n",
    "    fpath = Path(dirs[\"LOF\"]) / f\"{mrn}.nii.gz\"\n",
    "    if not fpath.exists():\n",
    "        fpath = Path(dirs[\"LOF\"]) / f\"{mrn}.nii\"\n",
    "    if not fpath.exists():\n",
    "        entry[\"LOF\"] = np.nan\n",
    "        print(f\"   âŒ LOF prediction missing\")\n",
    "    else:\n",
    "        fiss = (nib.load(fpath).get_fdata() > 0).astype(np.uint8)\n",
    "        cov, tot = get_covered_and_total(fiss, lob, *junctions[\"LOF\"])\n",
    "        entry[\"LOF\"] = np.nan if tot == 0 else 100.0 * cov / tot\n",
    "        print(f\"   âœ… LOF: {entry['LOF']:.1f}% ({cov}/{tot})\")\n",
    "\n",
    "    # RHF\n",
    "    fpath = Path(dirs[\"RHF\"]) / f\"{mrn}.nii.gz\"\n",
    "    if not fpath.exists():\n",
    "        fpath = Path(dirs[\"RHF\"]) / f\"{mrn}.nii\"\n",
    "    if not fpath.exists():\n",
    "        entry[\"RHF\"] = np.nan\n",
    "        print(f\"   âŒ RHF prediction missing\")\n",
    "    else:\n",
    "        fiss = (nib.load(fpath).get_fdata() > 0).astype(np.uint8)\n",
    "        cov, tot = get_covered_and_total(fiss, lob, *junctions[\"RHF\"])\n",
    "        entry[\"RHF\"] = np.nan if tot == 0 else 100.0 * cov / tot\n",
    "        cov_tot_sum[0] += cov\n",
    "        cov_tot_sum[1] += tot\n",
    "        rul_cov_tot[0] += cov\n",
    "        rul_cov_tot[1] += tot\n",
    "        print(f\"   âœ… RHF: {entry['RHF']:.1f}% ({cov}/{tot})\")\n",
    "\n",
    "    # ROF\n",
    "    fpath = Path(dirs[\"ROF\"]) / f\"{mrn}.nii.gz\"\n",
    "    if not fpath.exists():\n",
    "        fpath = Path(dirs[\"ROF\"]) / f\"{mrn}.nii\"\n",
    "    if not fpath.exists():\n",
    "        entry[\"ROF_combined\"] = np.nan\n",
    "        print(f\"   âŒ ROF prediction missing\")\n",
    "    else:\n",
    "        fiss = (nib.load(fpath).get_fdata() > 0).astype(np.uint8)\n",
    "        rof_total_cov = rof_total_tot = 0\n",
    "        cov1, tot1 = get_covered_and_total(fiss, lob, *junctions[\"ROF1\"])\n",
    "        rof_total_cov += cov1\n",
    "        rof_total_tot += tot1\n",
    "        rul_cov_tot[0] += cov1\n",
    "        rul_cov_tot[1] += tot1\n",
    "        print(f\"   ğŸ“Š ROF1 (1â†”3): ({cov1}/{tot1})\")\n",
    "        cov2, tot2 = get_covered_and_total(fiss, lob, *junctions[\"ROF2\"])\n",
    "        rof_total_cov += cov2\n",
    "        rof_total_tot += tot2\n",
    "        print(f\"   ğŸ“Š ROF2 (2â†”3): ({cov2}/{tot2})\")\n",
    "        entry[\"ROF_combined\"] = np.nan if rof_total_tot == 0 else 100.0 * rof_total_cov / rof_total_tot\n",
    "        print(f\"   âœ… ROF Combined: {entry['ROF_combined']:.1f}% ({rof_total_cov}/{rof_total_tot})\")\n",
    "        cov_tot_sum[0] += cov2\n",
    "        cov_tot_sum[1] += tot2\n",
    "\n",
    "    entry[\"RML1\"] = np.nan if cov_tot_sum[1] == 0 else 100.0 * cov_tot_sum[0] / cov_tot_sum[1]\n",
    "    print(f\"   âœ… RML1 (RHF+ROF2): {entry['RML1']:.1f}% ({cov_tot_sum[0]}/{cov_tot_sum[1]})\")\n",
    "\n",
    "    entry[\"RUL\"] = np.nan if rul_cov_tot[1] == 0 else 100.0 * rul_cov_tot[0] / rul_cov_tot[1]\n",
    "    print(f\"   âœ… RUL (RHF+ROF1): {entry['RUL']:.1f}% ({rul_cov_tot[0]}/{rul_cov_tot[1]})\")\n",
    "\n",
    "    records.append(entry)\n",
    "\n",
    "df = pd.DataFrame(records).sort_values(\"MRN\").reset_index(drop=True)\n",
    "df.to_excel(out_xls, index=False)\n",
    "print(f\"\\nâœ… Saved to {out_xls}\")\n",
    "print(f\"ğŸ“Š Processed {len(records)} MRNs total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8e38a",
   "metadata": {},
   "source": [
    "## Quality check of the predicted fissures vs lobe borders - StratX dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, nibabel as nib, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Parameters ===\n",
    "threshold_fissure_far_from_border = 30\n",
    "threshold_multiple_borders = 30\n",
    "\n",
    "# === Paths ===\n",
    "root_dir = r\"------ INSERT PATH HERE ------\"\n",
    "lobes_dir = os.path.join(root_dir, \"pred_folder_lobes134_best25003dEdited_2500\")\n",
    "fissure_dirs = {\n",
    "    \"LOF\": os.path.join(root_dir, \"pred_folder_LOF134_best5000\"),\n",
    "    \"ROF\": os.path.join(root_dir, \"pred_folder_ROF134_best5000\"),\n",
    "    \"RHF\": os.path.join(root_dir, \"pred_folder_RHF134_best5000\"),\n",
    "}\n",
    "out_xls = os.path.join(root_dir, \"fissure_not_amenable_summary_final.xlsx\")\n",
    "\n",
    "# === Define fissure border pairs ===\n",
    "fissure_defs = {\n",
    "    \"LOF\": [(4, 5)],\n",
    "    \"ROF\": [(1, 3), (2, 3)],\n",
    "    \"RHF\": [(1, 2)],\n",
    "    \"RML\": [(1, 2), (2, 3)],\n",
    "    \"RUL\": [(1, 2), (1, 3)],\n",
    "}\n",
    "\n",
    "def strip_nii(name): return name.replace(\".nii.gz\", \"\").replace(\".nii\", \"\")\n",
    "\n",
    "# === MRNs with all files present ===\n",
    "lobes_mrns = {strip_nii(f.name) for f in Path(lobes_dir).glob(\"*.nii*\")}\n",
    "fissure_mrns = {k: {strip_nii(f.name) for f in Path(v).glob(\"*.nii*\")} for k, v in fissure_dirs.items()}\n",
    "common_mrns = lobes_mrns & fissure_mrns[\"ROF\"] & fissure_mrns[\"RHF\"] & fissure_mrns[\"LOF\"]\n",
    "\n",
    "# === Processing loop ===\n",
    "all_results = []\n",
    "\n",
    "for idx, mrn in enumerate(sorted(common_mrns), 1):\n",
    "    print(f\"\\nğŸ”„ [{idx}/{len(common_mrns)}] Processing MRN: {mrn}\")\n",
    "    lobes_path = os.path.join(lobes_dir, f\"{mrn}.nii.gz\")\n",
    "    if not os.path.exists(lobes_path):\n",
    "        lobes_path = os.path.join(lobes_dir, f\"{mrn}.nii\")\n",
    "    lobes = nib.load(lobes_path).get_fdata().astype(np.uint8)\n",
    "\n",
    "    fissures = {\n",
    "        k: (nib.load(os.path.join(d, f\"{mrn}.nii.gz\")).get_fdata() > 0).astype(np.uint8)\n",
    "        for k, d in fissure_dirs.items()\n",
    "    }\n",
    "\n",
    "    H, D, W = lobes.shape\n",
    "    mrn_result = {\"MRN\": mrn}\n",
    "\n",
    "    for fissure_name, border_pairs in fissure_defs.items():\n",
    "        print(f\"   â¤ Fissure: {fissure_name}\")\n",
    "        total = 0\n",
    "        not_amenable = 0\n",
    "\n",
    "        for (A, B) in border_pairs:\n",
    "            # Fissure prediction source\n",
    "            if fissure_name in [\"RML\", \"RUL\"]:\n",
    "                if (A, B) == (1, 2):\n",
    "                    fissure_pred = fissures[\"RHF\"]\n",
    "                elif (A, B) == (2, 3) or (A, B) == (1, 3):\n",
    "                    fissure_pred = fissures[\"ROF\"]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected lobe pair for {fissure_name} in MRN {mrn}: ({A}, {B})\")\n",
    "            else:\n",
    "                fissure_pred = fissures[fissure_name]\n",
    "\n",
    "            for y in range(D):\n",
    "                for x in range(H):\n",
    "                    line = lobes[x, y, :]\n",
    "                    line_pred = fissure_pred[x, y, :]\n",
    "\n",
    "                    if A not in line or B not in line:\n",
    "                        continue\n",
    "                    total += 1\n",
    "\n",
    "                    border_rows = []\n",
    "                    for z in range(W):\n",
    "                        if line[z] == A and np.any(line[max(0, z-1):z+2] == B):\n",
    "                            border_rows.append(z)\n",
    "                        elif line[z] == B and np.any(line[max(0, z-1):z+2] == A):\n",
    "                            border_rows.append(z)\n",
    "\n",
    "                    fissure_rows = np.where(line_pred > 0)[0]\n",
    "\n",
    "                    # Heuristic 1\n",
    "                    if len(fissure_rows) > 0 and len(border_rows) > 0:\n",
    "                        min_dist = min([np.min(np.abs(fissure_rows - b)) for b in border_rows])\n",
    "                        if min_dist > threshold_fissure_far_from_border:\n",
    "                            not_amenable += 1\n",
    "                            continue\n",
    "\n",
    "                    # Heuristic 2\n",
    "                    if len(border_rows) > 1 and (np.max(border_rows) - np.min(border_rows) > threshold_multiple_borders):\n",
    "                        not_amenable += 1\n",
    "                        continue\n",
    "\n",
    "        percent = 100 * not_amenable / total if total else 0\n",
    "        mrn_result[f\"{fissure_name}_not_amenable\"] = not_amenable\n",
    "        mrn_result[f\"{fissure_name}_total\"] = total\n",
    "        mrn_result[f\"{fissure_name}_percent\"] = round(percent, 2)\n",
    "        print(f\"     â¬…ï¸ {fissure_name}: {not_amenable}/{total} not amenable ({percent:.2f}%)\")\n",
    "\n",
    "    all_results.append(mrn_result)\n",
    "\n",
    "# === Format and Save as Excel ===\n",
    "df = pd.DataFrame(all_results)\n",
    "fissures_order = [\"LOF\", \"RHF\", \"RML\", \"RUL\", \"ROF\"]\n",
    "metrics = [\"not_amenable\", \"total\", \"percent\"]\n",
    "ordered_cols = [\"MRN\"] + [f\"{f}_{m}\" for f in fissures_order for m in metrics]\n",
    "df = df.reindex(columns=ordered_cols)\n",
    "\n",
    "df.to_excel(out_xls, index=False)\n",
    "print(f\"\\nâœ… Saved summary to: {out_xls}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbdf50",
   "metadata": {},
   "source": [
    "## Scatter plotting the completeness scores with Pearson's correlation coefficient and regression line (with 95% CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74969abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy.stats as stats\n",
    "\n",
    "# === Load all columns from a single file ===\n",
    "df = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise_S_2.xlsx\")\n",
    "\n",
    "# === Setup 2x2 plot ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# === Helper function with 95% CI shading (NO ICC) ===\n",
    "def plot_and_stats(df, stratx_col, model_col, mrn_col, title, ax):\n",
    "    x = df[stratx_col]  # Reference\n",
    "    y = df[model_col]   # Model\n",
    "    mrns = df[mrn_col]\n",
    "\n",
    "    sorted_idx = np.argsort(x)\n",
    "    x_sorted = x.values[sorted_idx]\n",
    "    y_sorted = y.values[sorted_idx]\n",
    "    mrns_sorted = mrns.values[sorted_idx]\n",
    "\n",
    "    x_vals = x_sorted.reshape(-1, 1)\n",
    "    mdl = LinearRegression().fit(x_vals, y_sorted)\n",
    "    yhat = mdl.predict(x_vals)\n",
    "    r2 = r2_score(y_sorted, yhat)\n",
    "\n",
    "    n = len(x_vals)\n",
    "    se = np.sqrt(np.sum((y_sorted - yhat) ** 2) / (n - 2))\n",
    "    tval = stats.t.ppf(0.975, df=n - 2)\n",
    "    mean_x = np.mean(x_sorted)\n",
    "    margin = tval * se * np.sqrt(1/n + (x_sorted - mean_x)**2 / np.sum((x_sorted - mean_x)**2))\n",
    "    lower = yhat - margin\n",
    "    upper = yhat + margin\n",
    "\n",
    "    # Pearson r\n",
    "    r, p_r = stats.pearsonr(x, y)\n",
    "\n",
    "    # Plot\n",
    "    ax.fill_between(x_sorted, lower, upper, color='lightblue', alpha=0.3, label=\"95% CI\")\n",
    "    ax.plot(x_sorted, yhat, 'r', lw=1.5, label=f\"Linear Fit  $R^2$={r2:.2f}\")\n",
    "    ax.scatter(x, y, alpha=0.6)\n",
    "\n",
    "    for xi, yi, m in zip(x, y, mrns):\n",
    "        ax.annotate(m, (xi, yi), fontsize=7, alpha=.6)\n",
    "\n",
    "    ax.set(\n",
    "        title=title,\n",
    "        xlabel=f\"{stratx_col} (StratX Reference) [%]\",\n",
    "        ylabel=f\"{model_col} (Model Prediction) [%]\",\n",
    "        xlim=(0, 100),\n",
    "        ylim=(0, 100)\n",
    "    )\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    txt = f\"$r$ = {r:.2f}  (p = {p_r:.3f})\"\n",
    "    ax.text(0.02, 0.98, txt, transform=ax.transAxes,\n",
    "            va=\"top\", ha=\"left\", fontsize=9,\n",
    "            bbox=dict(facecolor=\"white\", alpha=.8, edgecolor=\"none\"))\n",
    "\n",
    "# === Drop NaNs ===\n",
    "df = df.dropna(subset=[\"MRN\", \"LOF\", \"LLL\", \"ROF\", \"RLL\", \"RML1\", \"RML\", \"RUL1\", \"RUL\"]).copy()\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# === Plot comparisons (switched subplot 2 and 3) ===\n",
    "plot_and_stats(df, \"LLL\", \"LOF\", \"MRN\", \"LOF (Model) vs LLL (StratX)\", axes[0, 0])\n",
    "plot_and_stats(df, \"RLL\", \"ROF\", \"MRN\", \"ROF (Model) vs RLL (StratX)\", axes[0, 1]) \n",
    "plot_and_stats(df, \"RUL\", \"RUL1\", \"MRN\", \"RUL (Model) vs RUL (StratX)\", axes[1, 0])  \n",
    "plot_and_stats(df, \"RML\", \"RML1\", \"MRN\", \"RML (Model) vs RML (StratX)\", axes[1, 1])\n",
    "\n",
    "# === Final layout ===\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ddacd",
   "metadata": {},
   "source": [
    "## Scatter plotting the completeness scores with Spearman's correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e141663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# === Load all columns from a single file ===\n",
    "df = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise_S_2.xlsx\")\n",
    "\n",
    "# === Drop NaNs and ensure numeric ===\n",
    "df = df.dropna(subset=[\"MRN\", \"LOF\", \"LLL\", \"ROF\", \"RLL\", \"RML1\", \"RML\", \"RUL1\", \"RUL\"]).copy()\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# === Setup 2x2 plot ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# === Helper function using Spearman and LOWESS ===\n",
    "def plot_and_stats(df, stratx_col, model_col, title, ax):\n",
    "    x = df[stratx_col]\n",
    "    y = df[model_col]\n",
    "\n",
    "    # Spearman correlation\n",
    "    rho, p_s = stats.spearmanr(x, y)\n",
    "\n",
    "    # Scatter plot with LOWESS trend\n",
    "    sns.scatterplot(x=x, y=y, ax=ax, alpha=0.6)\n",
    "    sns.regplot(x=x, y=y, ax=ax, lowess=True, scatter=False, color='red', label=\"LOWESS Trend\")\n",
    "\n",
    "    # Axes and titles\n",
    "    ax.set(\n",
    "        title=title,\n",
    "        xlabel=f\"{stratx_col} (StratX Reference) [%]\",\n",
    "        ylabel=f\"{model_col} (Model Prediction) [%]\",\n",
    "        xlim=(0, 100),\n",
    "        ylim=(0, 100)\n",
    "    )\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # Annotate Spearman's rho\n",
    "    txt = f\"$\\\\rho$ = {rho:.2f}  (p = {p_s:.3f})\"\n",
    "    ax.text(0.02, 0.98, txt, transform=ax.transAxes,\n",
    "            va=\"top\", ha=\"left\", fontsize=9,\n",
    "            bbox=dict(facecolor=\"white\", alpha=.8, edgecolor=\"none\"))\n",
    "\n",
    "# === Generate plots ===\n",
    "plot_and_stats(df, \"LLL\", \"LOF\", \"A. Left oblique fissure\", axes[0, 0])\n",
    "plot_and_stats(df, \"RLL\", \"ROF\", \"B. Right oblique fissure\", axes[0, 1]) \n",
    "plot_and_stats(df, \"RUL\", \"RUL1\", \"C. Fissures around Right upper lobe\", axes[1, 0])  \n",
    "plot_and_stats(df, \"RML\", \"RML1\", \"D. Fissures around Right middle lobe\", axes[1, 1])\n",
    "\n",
    "# === Final layout ===\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"------ INSERT PATH HERE ------\\Figure3.png\", dpi=300, bbox_inches='tight')  # Save at 300 DPI\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324e44a",
   "metadata": {},
   "source": [
    "## Model-derived completeness scores correlation and absolute agreement with StratX scores - Spearman correlation coefficient and ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5faeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise_S_2.xlsx\")\n",
    "df = df.dropna(subset=[\"MRN\", \"LOF\", \"LLL\", \"ROF\", \"RLL\", \"RML1\", \"RML\", \"RUL1\", \"RUL\"]).copy()\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# === Function to compute statistics ===\n",
    "def compute_metrics(df, model_col, stratx_col, id_col='MRN'):\n",
    "    df_pair = df[[id_col, model_col, stratx_col]].dropna()\n",
    "\n",
    "    # ICC(3,1)\n",
    "    df_long = df_pair.melt(id_vars=id_col, value_vars=[model_col, stratx_col],\n",
    "                           var_name='rater', value_name='score')\n",
    "    df_long['rater'] = df_long['rater'].map({model_col: \"Model\", stratx_col: \"StratX\"})\n",
    "    icc_result = pg.intraclass_corr(data=df_long, targets=id_col, raters='rater', ratings='score')\n",
    "    icc_row = icc_result[icc_result[\"Type\"] == \"ICC3\"].iloc[0]\n",
    "\n",
    "    # Spearman rho with 95% CI (using Fisher z)\n",
    "    x = df_pair[model_col]\n",
    "    y = df_pair[stratx_col]\n",
    "    rho, p = spearmanr(x, y)\n",
    "    n = len(x)\n",
    "    if abs(rho) == 1:  # Avoid infinity in arctanh for perfect correlation\n",
    "        lo, hi = rho, rho\n",
    "    else:\n",
    "        stderr = 1.0 / np.sqrt(n - 3)\n",
    "        delta = 1.96 * stderr\n",
    "        z = np.arctanh(rho)\n",
    "        lo = np.tanh(z - delta)\n",
    "        hi = np.tanh(z + delta)\n",
    "\n",
    "    return {\n",
    "        \"Comparison\": f\"{model_col} vs {stratx_col}\",\n",
    "        \"Spearman Ï (95% CI)\": f\"{rho:.2f} ({lo:.2f}â€“{hi:.2f})\",\n",
    "        \"Spearman p\": f\"{p:.3g}\",\n",
    "        \"ICC(3,1) (95% CI)\": f\"{icc_row['ICC']:.2f} ({icc_row['CI95%'][0]:.2f}â€“{icc_row['CI95%'][1]:.2f})\",\n",
    "        \"ICC p\": f\"{icc_row['pval']:.3g}\"\n",
    "    }\n",
    "\n",
    "# === Comparisons in specified order ===\n",
    "results = []\n",
    "pairs = [\n",
    "    ('LOF', 'LLL'),\n",
    "    ('ROF', 'RLL'),\n",
    "    ('RUL1', 'RUL'),\n",
    "    ('RML1', 'RML')\n",
    "]\n",
    "\n",
    "for model_col, stratx_col in pairs:\n",
    "    results.append(compute_metrics(df, model_col, stratx_col))\n",
    "\n",
    "# === Create and display results table ===\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903a13e",
   "metadata": {},
   "source": [
    "## Determining the optimal thresholds to predict the fissure completeness (>=95%) based on StratX values (with 95% CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e5dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Load and preprocess data ===\n",
    "df = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise_S_2.xlsx\")\n",
    "df = df.dropna(subset=[\"MRN\", \"LOF\", \"LLL\", \"ROF\", \"RLL\", \"RML1\", \"RML\", \"RUL1\", \"RUL\"]).copy()\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# === Fissure model/reference pairs ===\n",
    "pairs = [\n",
    "    ('LOF', 'LLL'),\n",
    "    ('ROF', 'RLL'),\n",
    "    ('RUL1', 'RUL'),\n",
    "    ('RML1', 'RML')\n",
    "]\n",
    "\n",
    "# === Bootstrap helper ===\n",
    "def bootstrap_metrics(y_true, y_scores, n_bootstraps=1000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    stats_list = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.choice(len(y_true), len(y_true), replace=True)\n",
    "        y_true_b = y_true[indices]\n",
    "        y_scores_b = y_scores[indices]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_b, y_scores_b)\n",
    "        youden = tpr - fpr\n",
    "        max_idx = np.argmax(youden)\n",
    "\n",
    "        best_thresh = thresholds[max_idx]\n",
    "        sens = tpr[max_idx]\n",
    "        spec = 1 - fpr[max_idx]\n",
    "        youden_val = youden[max_idx]\n",
    "        auc_val = auc(fpr, tpr)\n",
    "\n",
    "        stats_list.append([best_thresh, sens, spec, youden_val, auc_val])\n",
    "\n",
    "    stats_arr = np.array(stats_list)\n",
    "    means = np.mean(stats_arr, axis=0)\n",
    "    lower = np.percentile(stats_arr, 2.5, axis=0)\n",
    "    upper = np.percentile(stats_arr, 97.5, axis=0)\n",
    "\n",
    "    return {\n",
    "        \"Best Threshold (95% CI)\": f\"{means[0]:.2f} ({lower[0]:.2f}â€“{upper[0]:.2f})\",\n",
    "        \"Sensitivity (95% CI)\": f\"{means[1]:.3f} ({lower[1]:.3f}â€“{upper[1]:.3f})\",\n",
    "        \"Specificity (95% CI)\": f\"{means[2]:.3f} ({lower[2]:.3f}â€“{upper[2]:.3f})\",\n",
    "        \"Youden Index (95% CI)\": f\"{means[3]:.3f} ({lower[3]:.3f}â€“{upper[3]:.3f})\",\n",
    "        \"AUC (95% CI)\": f\"{means[4]:.3f} ({lower[4]:.3f}â€“{upper[4]:.3f})\"\n",
    "    }\n",
    "\n",
    "# === Run for individual fissures ===\n",
    "results = []\n",
    "for model_col, stratx_col in tqdm(pairs, desc=\"Bootstrapping Fissures\"):\n",
    "    df_pair = df[[model_col, stratx_col]].dropna()\n",
    "    y_true = (df_pair[stratx_col] >= 95).astype(int).values\n",
    "    y_scores = df_pair[model_col].values\n",
    "    metrics = bootstrap_metrics(y_true, y_scores)\n",
    "    metrics[\"Fissure\"] = f\"{model_col} vs {stratx_col}\"\n",
    "    results.append(metrics)\n",
    "\n",
    "# === Combined analysis ===\n",
    "combined = pd.DataFrame()\n",
    "for model_col, stratx_col in pairs:\n",
    "    df_pair = df[[model_col, stratx_col]].dropna()\n",
    "    df_temp = pd.DataFrame({\n",
    "        \"model_score\": df_pair[model_col],\n",
    "        \"stratx_binary\": (df_pair[stratx_col] >= 95).astype(int)\n",
    "    })\n",
    "    combined = pd.concat([combined, df_temp], ignore_index=True)\n",
    "\n",
    "metrics_combined = bootstrap_metrics(\n",
    "    combined[\"stratx_binary\"].values, combined[\"model_score\"].values\n",
    ")\n",
    "metrics_combined[\"Fissure\"] = \"Combined\"\n",
    "results.append(metrics_combined)\n",
    "\n",
    "# === Final results table ===\n",
    "results_df = pd.DataFrame(results)\n",
    "cols_order = [\"Fissure\", \"Best Threshold (95% CI)\", \"Sensitivity (95% CI)\",\n",
    "              \"Specificity (95% CI)\", \"Youden Index (95% CI)\", \"AUC (95% CI)\"]\n",
    "results_df = results_df[cols_order]\n",
    "\n",
    "# === Display in notebook ===\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc644fdb",
   "metadata": {},
   "source": [
    "## ROC for fissure completeness - StratX 95% threshold based prediction of Complete Fissure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087401ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# === Load unified file ===\n",
    "df = pd.read_excel(r\"------ INSERT PATH HERE ------\\fissure_completeness_all_columnwise_S_2.xlsx\")\n",
    "\n",
    "# === Drop missing values for required columns ===\n",
    "df = df.dropna(subset=[\"MRN\", \"LOF\", \"LLL\", \"ROF\", \"RLL\", \"RML1\", \"RML\", \"RUL1\", \"RUL\"]).copy()\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# === Setup 2x2 plot ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# === Helper function for ROC with shaded CI ===\n",
    "def plot_roc_with_ci(df, stratx_col, model_col, title, ax, n_bootstraps=1000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    y_true = (df[stratx_col] >= 95).astype(int).values\n",
    "    y_score = df[model_col].values\n",
    "\n",
    "    # ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Bootstrap for CI\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_score), len(y_score))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        fpr_b, tpr_b, _ = roc_curve(y_true[indices], y_score[indices])\n",
    "        aucs.append(auc(fpr_b, tpr_b))\n",
    "\n",
    "        interp_tpr = np.interp(mean_fpr, fpr_b, tpr_b)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "\n",
    "    lower_tpr = np.maximum(mean_tpr - 1.96 * std_tpr, 0)\n",
    "    upper_tpr = np.minimum(mean_tpr + 1.96 * std_tpr, 1)\n",
    "\n",
    "    # AUC 95% CI\n",
    "    lower_auc = np.percentile(aucs, 2.5)\n",
    "    upper_auc = np.percentile(aucs, 97.5)\n",
    "\n",
    "    # Plot ROC + CI band\n",
    "    ax.plot(fpr, tpr, color='steelblue', lw=2, label=f\"AUC = {roc_auc:.2f} (95% CI: {lower_auc:.2f}â€“{upper_auc:.2f})\")\n",
    "    ax.fill_between(mean_fpr, lower_tpr, upper_tpr, color='steelblue', alpha=0.2, label=\"95% CI\")\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
    "\n",
    "    ax.set(title=title,\n",
    "           xlabel=\"False Positive Rate\",\n",
    "           ylabel=\"True Positive Rate\",\n",
    "           xlim=(0, 1),\n",
    "           ylim=(0, 1))\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "# === Plot (order: LOF, ROF, RUL, RML) ===\n",
    "plot_roc_with_ci(df, \"LLL\",  \"LOF\",  \"A. Left oblique fissure\", axes[0, 0])\n",
    "plot_roc_with_ci(df, \"RLL\",  \"ROF\",  \"B. Right oblique fissure \", axes[0, 1])\n",
    "plot_roc_with_ci(df, \"RUL\",  \"RUL1\", \"C. Fissures around right upper lobe\", axes[1, 0])\n",
    "plot_roc_with_ci(df, \"RML\",  \"RML1\", \"D. Fissures around right middle lobe\", axes[1, 1])\n",
    "\n",
    "# === Final layout ===\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"------ INSERT PATH HERE ------\\Figure4.png\", dpi=300, bbox_inches='tight')  # Save at 300 DPI\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
